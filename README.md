# Neuroscope

Code to visualise any given MLP neuron of a Transformer language model, especially via text examples that strongly activate it.

Strongly inspired by Neel Nanda's <https://neuroscope.io/>, hence the name.
See also <https://github.com/neelnanda-io/Neuroscope>
(but I preferred to write my own code).
What's new compared to it:

* Specifically adapted to gated activation functions like SwiGLU, which are largely used in recent open-weights LLMs. In particular, strong negative activations are possible.
* BUT I only actually made a visualisation for a few neurons. Let's be honest: for most neurons nobody will ever care.

In a future version, I would like to:

* Pre-compute more information about each neuron
* Actually upload the pre-computed data, so that it becomes easy to create your own visualisation for any neuron you're interested in. (For the moment we just have the summary data with things such as activation frequency for each neuron, but not where it activates.)
* Replace pickle by pt.

## Structure

Be aware that it takes more than a day to run it.

* ```a_dataset.py```: Take a subset of Dolma and tokenize it.
* ```b_activations.py```: Run the model on that dataset and store some metadata about each neuron, including the dataset indices of its largest activations.
* ```d_recompute_vis.py```: For each neuron from the given set, create a nice HTML file that shows its activations on the max/min dataset examples.
* ```b2_recompute``` and ```c_neuron_vis```: helper functions.
* ```results```: visualisations generated by the code, for a few selected neurons.
  * Each subdirectory represents a layer
    * Each subdirectory thereof represents a neuron
      * Open the ```vis.html``` in a browser (or VS code with an appropriate extension). Requires JavaScript.

## How to use

You *could* run the code but that takes more than a day.
Instead, the ```results``` directory contains an HTML file for a few neurons.
Open it in a browser (with JavaScript) or in VSCode if you have an appropriate extension.

**If** you want to reproduce the run, do the following steps:

```[bash]
python a_dataset.py --save_to dolma-small
python b_activations.py --model allenai/OLMo-7B-0424-hf
python d_recompute_vis.py --model allenai/OLMo-7B-0424-hf --neurons 28.4737 28.9766 31.9634 29.10900 30.10972 29.4180 #for example
```

Explanations:

* ```a_dataset.py```: Take a subset of Dolma and tokenize it.
* ```b_activations.py```: Run model on data and store some metadata about each neuron, including the dataset indices of its largest activations.
* ```d_recompute_vis.py```: For each neuron from the given set, create a nice HTML file that shows its activations on the max/min dataset examples.
