# Neuroscope

Code to visualise any given MLP neuron of a Transformer language model, especially via text examples that strongly activate it.

Strongly inspired by Neel Nanda's <https://neuroscope.io/>, hence the name.
See also <https://github.com/neelnanda-io/Neuroscope>
(I noticed too late that he published his code).
What's new compared to it:

* Specifically adapted to gated activation functions like SwiGLU, which are largely used in recent open-weights LLMs. In particular, strong negative activations are possible.
* BUT I only actually made a visualisation for a few neurons. Let's be honest: for most neurons nobody will ever care.

In a future version, I would like to:

* Pre-compute more information about each neuron
* Actually upload the pre-computed data, so that it becomes easy to create your own visualisation for any neuron you're interested in.

## Warning

In most of our code we used pickle.
We later noticed we could have used torch.save() and torch.load() instead,
which is more trustworthy and avoids trouble with different devices.
We still submit the code with pickle for consistency with the data we saved.
We plan to make it compatible with both in a later version.

We do not submit any of the actual pickle data.
So feel free to change your local version of the code.

## Structure

Be aware that it takes more than a day to run it.

* ```a_dataset.py```: Take a subset of Dolma and tokenize it.
* ```b_activations.py```: Run the model on that dataset and store some metadata about each neuron, including the dataset indices of its largest activations.
* ```d_recompute_vis.py```: For each neuron from the given set, create a nice HTML file that shows its activations on the max/min dataset examples.
* ```b2_recompute``` and ```c_neuron_vis```: helper functions.
* ```results```: visualisations generated by the code, for a few selected neurons.
  * Each subdirectory represents a layer
    * Each subdirectory thereof represents a neuron
      * Open the ```vis.html``` in a browser (or VS code with an appropriate extension). Requires JavaScript.

## How to use

You *could* run the code but that takes more than a day.
Instead, the ```results``` directory contains an HTML file for a few neurons.
Open it in a browser (with JavaScript) or in VSCode if you have an appropriate extension.

**If** you want to reproduce the run, do the following steps:

```[bash]
python a_dataset.py --datadir YOUR_DATA_DIR --save_to dolma_small
python b_activations.py --model allenai/OLMo-7B-0424-hf --datadir YOUR_DATA_DIR --save_to results
python d_recompute_vis.py --model allenai/OLMo-7B-0424-hf --datadir YOUR_DATA_DIR --save_to results --neurons 28.4737 28.9766 31.9634 29.10900 30.10972 29.4180
```

Explanations:

* ```a_dataset.py```: Take a subset of Dolma and tokenize it.
* ```b_activations.py```: Run model on data and store some metadata about each neuron, including the dataset indices of its largest activations.
* ```d_recompute_vis.py```: For each neuron from the given set, create a nice HTML file that shows its activations on the max/min dataset examples.
